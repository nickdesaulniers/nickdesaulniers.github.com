<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ISA | Nick Desaulniers]]></title>
  <link href="http://nickdesaulniers.github.io/blog/categories/isa/atom.xml" rel="self"/>
  <link href="http://nickdesaulniers.github.io/"/>
  <updated>2020-04-06T08:08:18-07:00</updated>
  <id>http://nickdesaulniers.github.io/</id>
  <author>
    <name><![CDATA[Nick Desaulniers]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Data Models and Word Size]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2016/05/30/data-models-and-word-size/"/>
    <updated>2016-05-30T12:54:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2016/05/30/data-models-and-word-size</id>
    <content type="html"><![CDATA[<p><em>This post is a follow up to
<a href="/blog/2016/05/15/whats-in-a-word/">my previous blog post about word size</a>.</em></p>

<p>Three C/C++ programmers walk into a bar.  One argues that sizeof(void*) is
equivalent to sizeof(long), one argues that sizeof(void*) is equivalent to
sizeof(int), and the third argues it’s sizeof(long long).  Simultaneously,
they’re all right, but they’re also all wrong (and need a lesson about portable
C code).  What the hell is going on?</p>

<p>One of the first few programs a programmer might write after hello world is
something like this:</p>

<p>```c</p>

<h1>include &lt;stdio.h></h1>

<p>int main () {
  printf(&ldquo;sizeof(int): %zu\n&rdquo;, sizeof(int));
  printf(&ldquo;sizeof(long): %zu\n&rdquo;, sizeof(long));
  printf(&ldquo;sizeof(long long): %zu\n&rdquo;, sizeof(long long));
  printf(&ldquo;sizeof(void<em>): %zu\n&rdquo;, sizeof(void</em>));
}
```</p>

<p><em>Note the use of the %zu format specifier, a C99 addition that isn’t portable to
older compilers!  (This post is more about considerations when porting older
code to newer machines, not about porting newer code to run on older machines.
Not having a standards compliant C compiler makes writing more portable C code
even trickier, and is a subject for another blog post).</em></p>

<p>When I run that code on my x86-64 OSX machine, I get the following output:</p>

<p><code>sh
sizeof(int): 4
sizeof(long): 8
sizeof(long long): 8
sizeof(void*): 8
</code></p>

<p>So it looks like I would be the first programmer in the story in the first
paragraph, since on my machine, it looks like sizeof(long) == sizeof(void*).
Also note how sizeof(long long) is equivalent as well.</p>

<p>But what would happen if I compiled my code on a 32 bit machine?  Luckily, my
processor has backwards compatibility with 32b binaries, so I can cross compile
it locally and still run it. Ex:</p>

<p><code>sh
➜  clang sizeof.c -Wall -Wextra -Wpedantic
➜  file a.out
a.out: Mach-O 64-bit executable x86_64
➜  clang sizeof.c -Wall -Wextra -Wpedantic -m32
➜  file a.out
a.out: Mach-O executable i386
➜  ./a.out
sizeof(int): 4
sizeof(long): 4
sizeof(long long): 8
sizeof(void*): 4
</code></p>

<p>Huh, suddenly sizeof(void*) == sizeof(int) == sizeof(long)!  This seems
to be the case of the second programmer from the story.</p>

<p>Both programmer 1 and programmer 2 might agree that the size of a pointer is
equivalent to their machine’s respective
<a href="/blog/2016/05/15/whats-in-a-word/">word size</a>,
but that too would be an incorrect assumption for portable C/C++ code!</p>

<p>Programmer 3 goes through the hellscape that is installing a working compiler
for Windows and building a 64b command line application (to be fair, installing
command line tools for OSX is worse; installing a compiler for most OS’ leaves
much to be desired).  When they run that program, they see:</p>

<p><code>
sizeof(int): 4
sizeof(long): 4
sizeof(long long): 8
sizeof(void*): 8
</code></p>

<p>This is yet a third case (the third programmer from the story).  In this case,
only sizeof(long long) is equivalent to sizeof(void*).</p>

<h3>Data Models</h3>

<p>What these programmers are seeing is known as data models.  Programmer 1 one on
a 64b x86-64 OSX machine had an LP64 data model where longs (L), (larger long
longs,) and pointers (P) are 64b, but ints were 32b.  Programmer 2 on a 32b x86
OSX machine had an ILP32 data model where ints (I), longs (L), and pointers (P)
were 32b, but long longs were 64b.  Programmer 3 on a 64b x86-64 Windows
machine had a LLP64 data model, where only long longs (LL) and pointers (P)
were 64b, ints and longs being 32b.</p>

<table>
<thead>
<tr>
<th><strong>Data model</strong> </th>
<th> <strong>sizeof(int)</strong> </th>
<th> <strong>sizeof(long)</strong> </th>
<th> <strong>sizeof(long long)</strong> </th>
<th> <strong>sizeof(void*)</strong> </th>
<th> <strong>example</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>ILP32 </td>
<td> 32b </td>
<td> 32b </td>
<td> 64b </td>
<td> 32b </td>
<td> Win32, i386 OSX &amp; Linux</td>
</tr>
<tr>
<td>LP64 </td>
<td> 32b </td>
<td> 64b </td>
<td> 64b </td>
<td> 64b </td>
<td> x86-64 OSX &amp; Linux</td>
</tr>
<tr>
<td>LLP64 </td>
<td> 32b </td>
<td> 32b </td>
<td> 64b </td>
<td> 64b </td>
<td> Win64</td>
</tr>
</tbody>
</table>


<p>There are older data models such as LP32 (Windows 3.1, Macintosh, where ints
are 16b), and more exotic ones like ILP64, and SILP64.  Knowing the data model
thus is important for portable C/C++ code.</p>

<h3>Historical Perspective</h3>

<p>Running out of address space is and will continue to be tradition in computing.
Applications become bigger as computer power and memory gets cheaper.
Companies want to sell chips that have larger word sizes to address more
memory, but early adopters don’t want to buy a computer where there favorite
application hasn’t been compiled and thus doesn’t exist on yet.  <strong>Someone from
the back shouts <em>virtual machines</em> then ducks as a chair is thrown.</strong></p>

<p><a href="http://www.unix.org/version2/whatsnew/lp64_wp.html">This document</a>
highlights some reasons why LP64 is preferred to ILP64: ILP64
made portable C code that only needed 32b of precision harder to maintain (on
ILP64 an int was 64b, but a short was 16b!).  It mentions how for data
structures that did not contain pointers, their size would be the same on LLP64
as ILP32, which is the direction Microsoft went.  LLP64 was essentially the
ILP32 model with 64b pointers.</p>

<p><em>Linux also supports an ABI called
<a href="https://en.wikipedia.org/wiki/X32_ABI">x32</a>
which can use x86-64 ISA improvements but uses 32b pointers to reduce the size
of data structures that would otherwise have 64b pointers.</em></p>

<p>For a great historical perspective on the evolution of word size and data
models, as well as the &ldquo;toil and trouble&rdquo; caused,
<a href="https://queue.acm.org/detail.cfm?id=1165766">this paper</a>
was an excellent reference.  It describes Microsoft finally abandoning support
for 16b data models in Windows XP 64.  It mentions that the industry was pretty
split between LP64, LLP64, and ILP64 as porting code from the good old days of
ILP32 would break in different ways.  That the use of long was more prevalent
in Windows applications vs the use of int in unix applications.  It also makes
the key point that a lot of programmers from the ILP32 era made assumptions
that sizeof(int) == sizeof(long) == sizeof(void*) which would not hold true
for the LP64/LLP64 era.</p>

<p>One important point the paper makes makes that’s easily missed is that typedef
wasn’t added to C until 1977 when hardware manufactures still couldn’t agree on
how many bits were in a char (CHAR_BITS) and some machines were using 24b
addressing schemes.  stdint.h and inttypes.h did not exist yet.</p>

<p><a href="/blog/2016/05/15/whats-in-a-word/">This article</a>
talks about two main categories of effects of switching from ILP32 to LP64 and
has excellent examples of problematic code.  That section near the end is worth
the read alone and makes excellent points to look for during code review.</p>

<h3>Conclusion</h3>

<p>Word size or ISA doesn’t tell you anything about sizeof(int), sizeof(long), or
sizeof(long long).  We also saw that one machine can support multiple different
data models (when I compiled and ran the same code with the -m32 flag).</p>

<p>The C standard tells you minimum guaranteed sizes for these types, but the data
model (part of the ABI, external to but abiding by the C standard) is what
tells you about the specifics sizes of standard integers and pointers.</p>

<h3>Further Reading</h3>

<ul>
<li><a href="http://www.unix.org/version2/whatsnew/lp64_wp.html">64-Bit Programming Models: Why LP64?</a></li>
<li><a href="https://queue.acm.org/detail.cfm?id=1165766">The Long Road to 64 Bits</a></li>
<li><a href="http://www.unix.org/whitepapers/64bit.html">The UNIX System &mdash; 64bit and Data Size Neutrality</a></li>
<li><a href="https://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models">64-bit data models</a></li>
<li><a href="https://docs.oracle.com/cd/E19620-01/805-3024/lp64-1/index.html">C Language Data Type Models: LP64 and ILP32</a></li>
<li><a href="https://blogs.oracle.com/nike/entry/ilp64_lp64_llp64">ILP64, LP64, LLP64</a></li>
<li><a href="https://en.wikipedia.org/wiki/X32_ABI">x32 ABI</a></li>
<li><a href="http://stackoverflow.com/a/9162072">difference between stdint.h and inttypes.h</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa384083%28v=vs.85%29.aspx">Abstract Data Models</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa384264%28v=vs.85%29.aspx">The New Data Types</a></li>
<li><a href="http://stackoverflow.com/a/13413892">Is there any reason not to use fixed width integer types (e.g. uint8_t)?</a></li>
<li><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050131-00/?p=36563/">Why did the Win64 team choose the LLP64 model?</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What's in a Word?]]></title>
    <link href="http://nickdesaulniers.github.io/blog/2016/05/15/whats-in-a-word/"/>
    <updated>2016-05-15T17:58:00-07:00</updated>
    <id>http://nickdesaulniers.github.io/blog/2016/05/15/whats-in-a-word</id>
    <content type="html"><![CDATA[<p>Recently, there some was some confusion between myself and a coworker over the
definition of a &ldquo;word.&rdquo;  I&rsquo;m currently working on a blog post about data
alignment and figured it would be good to clarify some things now, that we can
refer to later.</p>

<p>Having studied computer engineering and being quite fond of processor design,
when I think of a &ldquo;word,&rdquo; I think of the number of bits wide a processor&rsquo;s
general purpose registers are
(aka <a href="https://en.wikipedia.org/wiki/Word_%28computer_architecture%29#Size_families">word size</a>).
This places hard requirements on the largest representable number and address
space.  A 64 bit processor can represent 2<sup>64</sup>-1 (1.8x10<sup>19</sup>) as the largest
unsigned long integer, and address up to 2<sup>64</sup>-1 (16 EiB) different addresses in
memory.</p>

<p>Further, word size limits the possible combinations of operations the processor
can perform, length of immediate values used, inflates the size of binary files
and memory needed to store pointers, and puts pressure on instruction caches.</p>

<p>Word size also has implications on loads and stores based on alignment, as
we&rsquo;ll see in a follow up post.</p>

<p>When I think of 8 bit computers, I think of my first microcontroller: an
Arduino with an Atmel AVR processor.  When I think of 16 bit computers, I think
of my first game console, a Super Nintendo with a Ricoh 5A22.  When I think of
32 bit computers, I think of my first desktop with Intel&rsquo;s Pentium III.  And
when I think of 64 bit computers, I think modern smartphones with ARMv8
instruction sets.  When someone mentions a particular word size, what are the
machines that come to mind for you?</p>

<p>So to me, when someone&rsquo;s talking about a 64b processor, to that machine (and
me) a word is 64b.  When we&rsquo;re referring to a 8b processor, a word is 8b.</p>

<p>Now, some confusion.</p>

<p>Back in my previous blog posts about
<a href="/blog/2014/04/18/lets-write-some-x86-64/">x86-64 assembly</a>,
<a href="/blog/2015/05/25/interpreter-compiler-jit/">JITs</a>, or
<a href="/blog/2016/01/20/debugging-x86-64-assembly-with-lldb-and-dtrace/">debugging</a>,
you might have seen me use instructions that have suffixes of b for byte (8b),
w for word (16b), dw for double word (32b), and qw for quad word (64b) (since
SSE2 there&rsquo;s also double quadwords of 128b).</p>

<p>Wait a minute!  How suddenly does a &ldquo;word&rdquo; refer to 16b on a 64b processor, as
opposed to a 64b &ldquo;word?&rdquo;</p>

<p>In short, historical baggage.  Intel&rsquo;s first hit processor was the
<a href="https://en.wikipedia.org/wiki/Intel_4004">4004</a>,
a 4b processor released in 1971.  It wasn&rsquo;t until 1979 that Intel created the
16b
<a href="https://en.wikipedia.org/wiki/Intel_8086">8086 processor</a>.</p>

<p>The 8086 was created to compete with other 16b processors that beat it to the
market, like the
<a href="https://en.wikipedia.org/wiki/Zilog_Z80">Zilog Z80</a>
(any Gameboy emulator fans out there?  Yes, I know about the Sharp LR35902).
The 8086 was the first design in the
<a href="https://en.wikipedia.org/wiki/X86">x86 family</a>,
and it allowed for the same assembly syntax from the earlier 8008, 8080, and
8085 to be reassembled for it.  The 8086&rsquo;s little brother (8088) would be used
in
<a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer#Open_standards">IBM&rsquo;s PC</a>,
and the rest is history.  x86 would become one of the most successful
ISAs in history.</p>

<p>For backwards compatibility, it seems that both Microsoft&rsquo;s (whose success has
tracked that of x86 since MS-DOS and IBM&rsquo;s PC) and Intel&rsquo;s documentation refers
to words still as being 16b. This allowed 16b PE32+ executables to be run on
32b or even 64b newer versions of Windows, without requiring recompilation of
source or source code modification.</p>

<p>This isn&rsquo;t necessarily wrong to refer to a word based on backwards
compatibility, it&rsquo;s just important to understand the context in which the term
&ldquo;word&rdquo; is being used, and that there might be some confusion if you have a
background with x86 assembly, Windows API programming, or processor design.</p>

<p>So the next time someone asks: why does Intel&rsquo;s documentation commonly refer to
a &ldquo;word&rdquo; as 16b, you can tell them that the x86 and x86-64 ISAs have maintained
the notion of a word being 16b since the first x86 processor, the 8086, which
was a 16b processor.</p>

<p><em>Side Note: for an excellent historical perspective programming early x86
chips, I recommend Michael Abrash&rsquo;s</em>
<a href="http://www.gamedev.net/page/resources/_/technical/graphics-programming-and-theory/graphics-programming-black-book-r1698">Graphics Programming Black Book</a>.
<em>For instance he talks about 8086&rsquo;s little brother, the 8088, being a 16b chip
but only having an 8b bus with which to access memory. This caused a mysterious</em>
<a href="http://downloads.gamedev.net/pdf/gpbb/gpbb4.pdf">&ldquo;cycle eater&rdquo;</a>
<em>to prevent fast access to 16b variables, though they were the processor&rsquo;s
natural size.  Michael also alludes to alignment issues we&rsquo;ll see in a follow
up post.</em></p>
]]></content>
  </entry>
  
</feed>
